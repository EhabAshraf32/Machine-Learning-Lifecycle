{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide 1: Introduction to Data Cleaning\n",
    "\n",
    "Data cleaning is a crucial step in the data analysis process. It involves identifying and correcting errors, inconsistencies, and inaccuracies in datasets to ensure the quality and reliability of your analysis. Python offers powerful tools and libraries for efficient data cleaning, making it an essential skill for any data scientist or analyst.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "A    1\n",
      "B    1\n",
      "C    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Example: Loading a dataset and checking for missing values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load a sample dataset\n",
    "df = {'A': [1, 2, np.nan, 4], 'B': [5, np.nan, 7, 8], 'C': [9, 10, 11, 12]}\n",
    "df=pd.DataFrame(df)\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide 2: Handling Missing Data\n",
    "\n",
    "One common issue in datasets is missing values. Python provides various methods to handle missing data, such as dropping rows with missing values or filling them with appropriate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     A    B   C\n",
      "0  1.0  5.0   9\n",
      "1  2.0  NaN  10\n",
      "2  NaN  7.0  11\n",
      "3  4.0  8.0  12\n",
      "\n",
      "DataFrame after dropping rows with missing values:\n",
      "     A    B   C\n",
      "0  1.0  5.0   9\n",
      "3  4.0  8.0  12\n",
      "\n",
      "DataFrame after filling missing values with column means:\n",
      "          A         B   C\n",
      "0  1.000000  5.000000   9\n",
      "1  2.000000  6.666667  10\n",
      "2  2.333333  7.000000  11\n",
      "3  4.000000  8.000000  12\n"
     ]
    }
   ],
   "source": [
    "# Example: Handling missing data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample dataset with missing values\n",
    "data = {'A': [1, 2, np.nan, 4], 'B': [5, np.nan, 7, 8], 'C': [9, 10, 11, 12]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_dropped = df.dropna()\n",
    "\n",
    "# Fill missing values with the mean of the column\n",
    "df_filled = df.fillna(df.mean())\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nDataFrame after dropping rows with missing values:\")\n",
    "print(df_dropped)\n",
    "print(\"\\nDataFrame after filling missing values with column means:\")\n",
    "print(df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide 3: Removing Duplicates\n",
    "Duplicate entries can skew your analysis and lead to incorrect conclusions. Python's pandas library offers simple methods to identify and remove duplicate rows from your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   A  B\n",
      "0  1  5\n",
      "1  2  6\n",
      "2  2  6\n",
      "3  3  7\n",
      "4  4  8\n",
      "\n",
      "Duplicate rows:\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n",
      "\n",
      "DataFrame after removing duplicates:\n",
      "   A  B\n",
      "0  1  5\n",
      "1  2  6\n",
      "3  3  7\n",
      "4  4  8\n"
     ]
    }
   ],
   "source": [
    "# Example: Removing duplicate rows\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataset with duplicate rows\n",
    "data = {'A': [1, 2, 2, 3, 4], 'B': [5, 6, 6, 7, 8]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Identify duplicate rows\n",
    "duplicates = df.duplicated()\n",
    "\n",
    "# Remove duplicate rows\n",
    "df_unique = df.drop_duplicates()\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nDuplicate rows:\")\n",
    "print(duplicates)\n",
    "print(\"\\nDataFrame after removing duplicates:\")\n",
    "print(df_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide 4: Handling Outliers\n",
    "\n",
    "Outliers can significantly impact your analysis and should be carefully handled. One common method is the Interquartile Range (IQR) technique to identify and remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   values\n",
      "0       1\n",
      "1       2\n",
      "2       3\n",
      "3       4\n",
      "4       5\n",
      "5       6\n",
      "6       7\n",
      "7       8\n",
      "8       9\n",
      "9     100\n",
      "\n",
      "DataFrame after removing outliers:\n",
      "   values\n",
      "0       1\n",
      "1       2\n",
      "2       3\n",
      "3       4\n",
      "4       5\n",
      "5       6\n",
      "6       7\n",
      "7       8\n",
      "8       9\n"
     ]
    }
   ],
   "source": [
    "# Example: Handling outliers using IQR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample dataset with outliers\n",
    "data = {'values': [1, 2, 3, 4, 5, 6, 7, 8, 9, 100]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate Q1, Q3, and IQR\n",
    "Q1 = df['values'].quantile(0.25)\n",
    "Q3 = df['values'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Remove outliers\n",
    "df_clean = df[(df['values'] >= lower_bound) & (df['values'] <= upper_bound)]\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nDataFrame after removing outliers:\")\n",
    "print(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide 5: Data Type Conversion\n",
    "\n",
    "Ensuring correct data types is crucial for accurate analysis. Python provides methods to check and convert data types as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data types:\n",
      "A    object\n",
      "B    object\n",
      "C    object\n",
      "dtype: object\n",
      "\n",
      "Converted data types:\n",
      "A      int32\n",
      "B    float64\n",
      "C       bool\n",
      "dtype: object\n",
      "\n",
      "Converted DataFrame:\n",
      "   A    B     C\n",
      "0  1  4.5  True\n",
      "1  2  5.5  True\n",
      "2  3  6.5  True\n"
     ]
    }
   ],
   "source": [
    "# Example: Converting data types\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataset with mixed data types\n",
    "data = {'A': ['1', '2', '3'], 'B': ['4.5', '5.5', '6.5'], 'C': ['True', 'False', 'True']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check initial data types\n",
    "print(\"Initial data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Convert data types\n",
    "df['A'] = df['A'].astype(int)\n",
    "df['B'] = df['B'].astype(float)\n",
    "df['C'] = df['C'].astype(bool)\n",
    "\n",
    "# Check converted data types\n",
    "print(\"\\nConverted data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nConverted DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide 6: String Cleaning and Normalization\n",
    "\n",
    "String data often requires cleaning and normalization to ensure consistency. This includes tasks like removing whitespace, converting to lowercase, and handling special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "{'names': [' John ', 'JANE', 'bob ', ' Alice']}\n",
      "\n",
      "Cleaned DataFrame:\n",
      "   names\n",
      "0   John\n",
      "1   Jane\n",
      "2    Bob\n",
      "3  Alice\n"
     ]
    }
   ],
   "source": [
    "# Example: String cleaning and normalization\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataset with messy string data\n",
    "data = {'names': [' John ', 'JANE', 'bob ', ' Alice']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Clean and normalize strings\n",
    "df['names'] = df['names'].str.strip().str.lower().str.capitalize()\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(data)\n",
    "print(\"\\nCleaned DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide 7: Handling Date and Time Data\n",
    "\n",
    "Date and time data often require special handling and conversion to ensure proper analysis and formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed DataFrame:\n",
      "       dates  year  month  day\n",
      "0 2023-01-01  2023      1    1\n",
      "1 2023-02-15  2023      2   15\n",
      "2 2023-03-30  2023      3   30\n"
     ]
    }
   ],
   "source": [
    "# Example: Handling date and time data\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataset with date strings\n",
    "data = {'dates': ['2023-01-01', '2023-02-15', '2023-03-30']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert string to datetime\n",
    "df['dates'] = pd.to_datetime(df['dates'])\n",
    "\n",
    "# Extract various components\n",
    "df['year'] = df['dates'].dt.year\n",
    "df['month'] = df['dates'].dt.month\n",
    "df['day'] = df['dates'].dt.day\n",
    "df['day_of_week'] = df['dates'].dt.day_name()\n",
    "\n",
    "# Then Drop the Main Column\n",
    "df.drop(columns=[\"day_of_week\"],inplace=True)\n",
    "\n",
    "print(\"Processed DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
